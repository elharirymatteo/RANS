# used to create the object
name: ASVVirtual

physics_engine: ${..physics_engine}
experiment: ASV_GoThroughPosition
enable_wandb_log: ${..wandb_activate}

defaults:
  - robot: ASV_kingfisher.yaml
  - disturbances: disable_disturbances.yaml
  - sub_task: GoThroughPosition.yaml
  - reward: GoThroughPosition.yaml
  - penalty: penalties.yaml
  - _self_

reward:
  heading_scale: 0.9
  time_penalty: 1.0

penalty:
  linear_velocity_penalty:
    enable: False

  angular_velocity_penalty:
    enable: True
    weight: 0.5
    scaling_function: linear
    min_value: 0.5
    max_value: 20.0
    curriculum:
      function: linear
      start: 5
      end: 10
  energy_penalty:
    enable: True
    weight: 0.5
    curriculum:
      function: linear
      start: 5
      end: 10

sub_task:
  name: GoThroughPosition
  position_tolerance: 0.1
  kill_after_n_steps_in_tolerance: 1 # 10seconds
  kill_dist: 15.0
  spawn_position_curriculum:
    rate_parameters:
      function: linear
      start: 1
      end: 100
      extent: 4.5
    sampling_parameters:
      distribution: truncated_normal
      start_mean: 3.0
      start_std: 1.5
      end_mean: 6.0
      end_std: 3.0
      min_value: 1.0
      max_value: 10.0
  spawn_heading_curriculum:
    rate_parameters:
      function: linear
      start: 1
      end: 100
      extent: 4.5
    sampling_parameters:
      distribution: truncated_normal
      start_mean: 0.0
      start_std: 0.25
      end_mean: 0.0 #2pi
      end_std: 4.71238898038469 #3/2 pi
      min_value: -3.141592653589793 # -pi
      max_value: 3.141592653589793 # pi
  spawn_linear_velocity_curriculum:
    rate_parameters:
      function: linear
      start: 1
      end: 100
      extent: 4.5
    sampling_parameters:
      distribution: truncated_normal
      start_mean: 0.0
      start_std: 0.0001
      end_mean: 1.0
      end_std: 0.5
      min_value: 0.0
      max_value: 1.5
  spawn_angular_velocity_curriculum:
    rate_parameters:
      function: linear
      start: 1
      end: 100
      extent: 4.5
    sampling_parameters:
      distribution: truncated_normal
      start_mean: 0.0
      start_std: 0.0001
      end_mean: 0.0
      end_std: 0.5
      min_value: -0.5
      max_value: 0.5

# if given, will override the device setting in gym. 
env:
  numEnvs: ${resolve_default:64,${...num_envs}}
  envSpacing: 12
  maxEpisodeLength: 1000
  enableDebugVis: False
  action_mode: Continuous
  numQuantizedActions: 1
  horizon_length: ${...train.params.config.horizon_length}

  controlFrequencyInv: 10
  observation_frame: "local"

  clipObservations: {state: 8.0}
  clipActions: 1.0

sim:
  dt: 0.02
  use_gpu_pipeline: ${eq:${...pipeline},"gpu"}
  gravity: [0.0, 0.0, -9.81]
  add_ground_plane: True
  add_distant_light: False
  use_fabric: True
  enable_scene_query_support: False
  disable_contact_processing: False

  # set to True if you use camera sensors in the environment
  enable_cameras: False

  physx:
    worker_thread_count: ${....num_threads}
    solver_type: ${....solver_type}
    use_gpu: ${eq:${....sim_device},"gpu"} # set to False to run on CPU
    solver_position_iteration_count: 4
    solver_velocity_iteration_count: 1
    contact_offset: 0.02
    rest_offset: 0.001
    bounce_threshold_velocity: 0.2
    friction_offset_threshold: 0.04
    friction_correlation_distance: 0.025
    enable_sleeping: True
    enable_stabilization: False
    max_depenetration_velocity: 100.0

    # GPU buffers
    gpu_max_rigid_contact_count: 524288
    gpu_max_rigid_patch_count: 81920
    gpu_found_lost_pairs_capacity: 1024
    gpu_found_lost_aggregate_pairs_capacity: 262144
    gpu_total_aggregate_pairs_capacity: 1024
    gpu_max_soft_body_contacts: 1048576
    gpu_max_particle_contacts: 1048576
    gpu_heap_capacity: 67108864
    gpu_temp_buffer_capacity: 16777216
    gpu_max_num_partitions: 8
